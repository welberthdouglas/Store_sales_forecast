{"cells":[{"metadata":{},"cell_type":"markdown","source":"# 1. Imports"},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"import numpy as n\nimport pandas as pd \nimport os\nimport seaborn as sns\nimport shap\n\nfrom datetime import datetime, timedelta\nfrom sklearn.model_selection import train_test_split,RandomizedSearchCV,GridSearchCV\nfrom sklearn.ensemble import RandomForestRegressor\nfrom sklearn.metrics import mean_absolute_error,mean_squared_error\n\npd.options.display.max_columns = None\npd.set_option('display.max_rows', None)\n\nseed = 42\n","execution_count":216,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# 2. Loading Data"},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"# train data\npath = '../input/walmart-recruiting-store-sales-forecasting/'\ntrain = pd.read_csv(path+'train.csv.zip')\nstores = pd.read_csv(path+'stores.csv')\nfeatures = pd.read_csv(path+'features.csv.zip')\n\n# test data\ntest = pd.read_csv(path+'test.csv.zip')","execution_count":217,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train.head()","execution_count":218,"outputs":[{"output_type":"execute_result","execution_count":218,"data":{"text/plain":"   Store  Dept        Date  Weekly_Sales  IsHoliday\n0      1     1  2010-02-05      24924.50      False\n1      1     1  2010-02-12      46039.49       True\n2      1     1  2010-02-19      41595.55      False\n3      1     1  2010-02-26      19403.54      False\n4      1     1  2010-03-05      21827.90      False","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Store</th>\n      <th>Dept</th>\n      <th>Date</th>\n      <th>Weekly_Sales</th>\n      <th>IsHoliday</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1</td>\n      <td>1</td>\n      <td>2010-02-05</td>\n      <td>24924.50</td>\n      <td>False</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1</td>\n      <td>1</td>\n      <td>2010-02-12</td>\n      <td>46039.49</td>\n      <td>True</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>1</td>\n      <td>1</td>\n      <td>2010-02-19</td>\n      <td>41595.55</td>\n      <td>False</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>1</td>\n      <td>1</td>\n      <td>2010-02-26</td>\n      <td>19403.54</td>\n      <td>False</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>1</td>\n      <td>1</td>\n      <td>2010-03-05</td>\n      <td>21827.90</td>\n      <td>False</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"metadata":{},"cell_type":"markdown","source":"# 3. Joining Tables"},{"metadata":{},"cell_type":"markdown","source":"## 3.1. Filling missing dates\n\n\nSome Store Departments have no data for some weeks so we are going to input these instances with zero sales"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Creating new index\ndates = train.Date.sort_values().unique()\ndepts = train.Dept.sort_values().unique()\nstrs = train.Store.sort_values().unique()\n\nfill_index = pd.MultiIndex.from_product([dates, strs, depts],\n                           names=['Date','Store','Dept'])\n\n# Creating holidays dataframe\nholidays = train.query('Store==1 & Dept==1')[['Date','IsHoliday']]\n\n\n# Filling with reindex\ntrain_new = train.set_index(['Date','Store','Dept']).Weekly_Sales.reindex(fill_index, fill_value = 0)\ntrain_new = train_new.to_frame()\ntrain_new.reset_index(inplace=True)\n\n# merging back with holidays\n\ntrain_new = train_new.merge(holidays, on='Date', how = 'left')\n","execution_count":219,"outputs":[{"output_type":"error","ename":"KeyboardInterrupt","evalue":"","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-219-917e4ab1cc32>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m fill_index = pd.MultiIndex.from_product([dates, strs, depts],\n\u001b[0;32m----> 7\u001b[0;31m                            names=['Date','Store','Dept'])\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;31m# Creating holidays dataframe\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.6/site-packages/pandas/core/indexes/multi.py\u001b[0m in \u001b[0;36mfrom_product\u001b[0;34m(cls, iterables, sortorder, names)\u001b[0m\n\u001b[1;32m    538\u001b[0m         \u001b[0mcodes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlevels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_factorize_from_iterables\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterables\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    539\u001b[0m         \u001b[0mcodes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcartesian_product\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcodes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 540\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mMultiIndex\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlevels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcodes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msortorder\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msortorder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnames\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnames\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    541\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    542\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mclassmethod\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.6/site-packages/pandas/util/_decorators.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    206\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    207\u001b[0m                     \u001b[0mkwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mnew_arg_name\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnew_arg_value\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 208\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    209\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    210\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.6/site-packages/pandas/core/indexes/multi.py\u001b[0m in \u001b[0;36m__new__\u001b[0;34m(cls, levels, codes, sortorder, names, dtype, copy, name, verify_integrity, _set_identity)\u001b[0m\n\u001b[1;32m    270\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    271\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mverify_integrity\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 272\u001b[0;31m             \u001b[0mnew_codes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_verify_integrity\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    273\u001b[0m             \u001b[0mresult\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_codes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnew_codes\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    274\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.6/site-packages/pandas/core/indexes/multi.py\u001b[0m in \u001b[0;36m_verify_integrity\u001b[0;34m(self, codes, levels)\u001b[0m\n\u001b[1;32m    336\u001b[0m                     \u001b[0;34m\"Unequal code lengths: %s\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcode_\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mcode_\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mcodes\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    337\u001b[0m                 )\n\u001b[0;32m--> 338\u001b[0;31m             \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlevel_codes\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mlevel_codes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlevel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    339\u001b[0m                 msg = (\n\u001b[1;32m    340\u001b[0m                     \u001b[0;34m\"On level {level}, code max ({max_code}) >= length of \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.6/site-packages/numpy/core/_methods.py\u001b[0m in \u001b[0;36m_amax\u001b[0;34m(a, axis, out, keepdims, initial, where)\u001b[0m\n\u001b[1;32m     28\u001b[0m def _amax(a, axis=None, out=None, keepdims=False,\n\u001b[1;32m     29\u001b[0m           initial=_NoValue, where=True):\n\u001b[0;32m---> 30\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mumr_maximum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkeepdims\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minitial\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwhere\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     31\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m def _amin(a, axis=None, out=None, keepdims=False,\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}]},{"metadata":{},"cell_type":"markdown","source":"## 3.2. Merge\n\nMerging the new train dataset with Stores and Features "},{"metadata":{"trusted":true},"cell_type":"code","source":"data = train_new.merge(stores, on = 'Store', how = 'left').merge(features.drop(columns=['IsHoliday']), on =['Store','Date'], how = 'left')\n\n#data.IsHoliday_x.equals(data.IsHoliday_y)  # columns are equal so one can be dropped\n\ndata.to_csv(\"data.csv\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# 4. Initial Exploration"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Describe\ndata.describe().T","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Types\nprint(data.head(),'\\n\\n',data.dtypes) # datatypes are all good","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Check for Nulls\nprint(data.count(),'\\n\\n',data.isna().sum()) # null values only on markdown columns","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Stores entries\n# data['Store'].value_counts()  # some stores have slightly more entries than others...\n\n# this was fixed using imputation ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data.groupby(['Store','Dept']).agg(dates = ('Date', 'count'))\n\n# all departments now have the same number of entries","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Analisis Ideas\n\n# Total Sales by department\n# Total Sales by store\n# Pairplot","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# 5. Feature Engineering\n\n- OK - Parse Dates to label encoding (months and weeks of the year)\n- OK - Encode variable \"Type\" (one hot)\n- Create variables #weeks before holiday\n- OK - Input missing Dept instances as zero sales (treating missing data as zero sales)\n- OK - What are negative sales? (1285 entries in the test database  = 0.3% max of -4988.94 and total of -88161.56 adding up to -0,000013086% of the total sales) replace with zero?\n- OK - Fill Nulls in markdown variables\n\n\n\n## Features to create for the test dataset - Out of Time (if proven to be inportant to the prediction): \n- Forecast Temperatures (seasonal ) as function of week of the year\n- Forecast Fuel Prices as an average of the last year price\n- Forecast CPI (linear regression) as function of week of the year\n- Forecast Unemployment (rectified linear regression with minimum bound as 2%)\n- See what to to With markdowns (if important to sales prediction)"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Replacing Negative Sales with 0\ndata[data.Weekly_Sales < 0 ].Weekly_Sales = 0","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# FillNA markdown variables with -9999\ndata.fillna(-9999,inplace = True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# OneHot encoding variable store type\ndata = pd.get_dummies(data,columns=['Type'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# parse data into month and weekofyear columns\ndata['Month'] = data.Date.apply(lambda x : datetime.strptime(str(x),'%Y-%m-%d').month)\ndata['WeekofYear'] = data.Date.apply(lambda x : datetime.strptime(str(x),'%Y-%m-%d').isocalendar()[1])\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# holidays weeks\ndata.query('IsHoliday == True').WeekofYear.unique()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data['IsHoliday'] = data.query('IsHoliday == True').WeekofYear\ndata['IsHoliday_1'] = data.query('WeekofYear in (5, 35, 46, 51)').WeekofYear","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data = pd.get_dummies(data,columns=['IsHoliday','IsHoliday_1'],prefix=['Holiday','Week_Before_Holiday'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Modeling"},{"metadata":{"trusted":true},"cell_type":"code","source":"X = data.drop(columns = ['Date','Weekly_Sales'])\ny = data.Weekly_Sales\n\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=seed)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_train.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_train.shape,y_train.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"rf = RandomForestRegressor(random_state=seed, n_jobs=-1)\nrandom_grid = {'bootstrap': [True, False],\n               'max_depth': [10, 20, 30, 40, 50, 60, 70, 80, 90, 100, None],\n               'max_features': ['auto', 'sqrt'],\n               'min_samples_leaf': [1, 2, 4],\n               'min_samples_split': [2, 5, 10],\n               'n_estimators': [200, 400, 600, 800, 1000, 1200, 1400, 1600, 1800, 2000]}\n\n\nrandom_grid = RandomizedSearchCV(estimator = rf, param_distributions = random_grid, n_iter = 100, cv = 3, random_state=seed, n_jobs = -1)\n\n# Fit the random search model\nrandom_grid.fit(X_train, y_train)\n\nprint(random_grid.best_params_)\n\nrand_reg = random_grid.best_estimator_.fit(X_train, y_train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"rand_reg.predict(X_train.head())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y_train.head(40)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(\"train MAE: {:.2f}\".format(mean_absolute_error(y_train,rand_reg.predict(X_train))))\nprint(\"test MAE: {:.2f}\".format(mean_absolute_error(y_test,rand_reg.predict(X_test))))\nprint(\"train RMSE: {:.2f}\".format(mean_squared_error(y_train, rand_reg.predict(X_train))**0.5))\nprint(\"test RMSE: {:.2f}\".format(mean_squared_error(y_test, rand_reg.predict(X_test))**0.5))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"imp_rf = pd.DataFrame(rand_reg.feature_importances_).transpose()\nimp_rf.columns = X_train.columns\nimp_rf = imp_rf.transpose().sort_values(0,ascending=False)\nimp_rf.columns = ['rf_importance']\n\nimp_rf.plot.barh()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"explainer = shap.TreeExplainer(rand_reg, approximate = True)\nrf_shap_values = explainer.shap_values(X_test.iloc[0:1000,:])\nshap.summary_plot(rf_shap_values, X_test.iloc[0:1000,:])","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}